# ğŸµ Raag Bihag composition by RNN-LSTM

This project is a simple deep learning-based melody generator built using TensorFlow/Keras. It uses an LSTM network trained on musical sequences to generate new melodies. The model outputs MIDI files which can be opened in music notation software like MuseScore for playback or editing.

## ğŸ“ Project Structure

  Code.ipynb â€” Main Jupyter Notebook with model training, melody generation, and inference logic.

  model.keras â€” Saved trained model (you may need to train and save it).

  mappings.json â€” A JSON file that maps musical symbols to integers and vice versa.

  melody.mid â€” Example output MIDI file generated by the model.
 ## ğŸ§  Model Architecture

  Input: One-hot encoded sequences of shape (None, 17)

  Layers:

  LSTM with 256 units

  Dropout layer

  Dense layer with softmax activation to predict the next note

  Output: Probability distribution over 17 possible note symbols
  ## Future Directions
  This model was trained on short compositional phrases (4-5 bars of music). As a result, the generated music is limited to short sequencesâ€”typically just a few   bars in length.

Currently, the model is best suited for experimenting with brief melodic or thematic ideas. In future iterations, I plan to extend the training dataset to include longer musical pieces. 
