{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18ba0f5f-2ef5-41be-acff-eb98643c5e7f",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe1b9313-1428-42f3-a91c-073c1da7869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import music21 as m21\n",
    "from music21 import converter, stream, environment, note\n",
    "from music21.pitch import Accidental\n",
    "import copy\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from keras.utils import plot_model\n",
    "\n",
    "\n",
    "us = environment.UserSettings()\n",
    "us['musicxmlPath'] = '/Applications/MuseScore 3.app/Contents/MacOS/mscore'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13d8baf-679d-4953-b65b-4c0c764a3cc2",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae414fba-531b-4f80-8bd2-7d5edd1b522d",
   "metadata": {},
   "source": [
    "Data (in kern format) download link: https://kern.humdrum.org/cgi-bin/browse?l=users/pchordia/bhatkhandve/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71436506-0f55-40b7-b011-03272e6092eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kern_data_set = \"Raag Bihag krn files\"\n",
    "save_dir = \"Raag Bihag text files\"\n",
    "single_file_dataset = \"single_file_dataset\"\n",
    "sequence_length = 64\n",
    "mapping_path = \"mapping.json\"\n",
    "acceptable_note_durations = [0.25, 0.5, 0.75, 1.0, 1.5, 2, 3, 4]\n",
    "\n",
    "us = environment.UserSettings()\n",
    "us['musicxmlPath'] = '/Applications/MuseScore 3.app/Contents/MacOS/mscore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d886e67-6e62-46c2-b40d-937a5ea5d06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a song list of all the songs parsed in music21 format\n",
    "def create_m21_songlist (data_set):\n",
    "    songs = []\n",
    "    for dirpath, dirnames, filenames in os.walk(data_set):\n",
    "        for file in filenames:\n",
    "            if file[-3:] == \"krn\":\n",
    "                file_path = os.path.join(dirpath,file)\n",
    "                #print(file_path)   \n",
    "                try:\n",
    "                    song = converter.parse(file_path)\n",
    "                    songs.append(song)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error parsing {file_path}: {e}\")\n",
    "    return songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bd832e5a-4ca0-4a2a-8fd3-3c40386ea6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The song contains \"acciaccatura\" notes. To avoid complications those notes were removed form the songs. \n",
    "\n",
    "def clean_songs(songs, acceptable_note_durations):\n",
    "    cleaned_songs = []\n",
    "\n",
    "    for song in songs:\n",
    "        cleaned_stream = stream.Stream()\n",
    "\n",
    "        for element in song.flat.notesAndRests:\n",
    "            if element.duration.quarterLength in acceptable_note_durations:\n",
    "                elem_copy = copy.deepcopy(element)  # deep copy the element\n",
    "                cleaned_stream.append(elem_copy)\n",
    "\n",
    "        cleaned_songs.append(cleaned_stream)\n",
    "\n",
    "    return cleaned_songs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bdc783a0-1b37-43e2-9944-961db9881832",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert song to time series format\n",
    "def time_series(song, time_step=0.25):\n",
    "    time_series = []\n",
    "\n",
    "    for element in song.flat.notesAndRests:\n",
    "        if isinstance(element, m21.note.Note):\n",
    "            value = element.pitch.midi  # fixed variable name from 'event' to 'element'\n",
    "        elif isinstance(element, m21.note.Rest):\n",
    "            value = \"r\"\n",
    "        else:\n",
    "            continue  # skip other elements like expressions or articulations\n",
    "\n",
    "        steps = int(element.duration.quarterLength / time_step)\n",
    "        for step in range(steps):\n",
    "            if step == 0:\n",
    "                time_series.append(value)\n",
    "            else:\n",
    "                time_series.append(\"_\")\n",
    "\n",
    "    # Convert all elements to string\n",
    "    time_series = map(str, time_series)\n",
    "\n",
    "    # Join with space\n",
    "    return \" \".join(time_series)\n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1191e73-1498-41e8-91af-32e30b7995e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_mapping(songs,mapping_path):\n",
    "    mappings = {}\n",
    "    songs = songs.split()\n",
    "    vocabulary = list(set(songs))\n",
    "    for i, symbol in enumerate(vocabulary):\n",
    "        mappings[symbol] = i\n",
    "    with open(mapping_path, \"w\") as fp:\n",
    "        json.dump(mappings,fp, indent=4)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ef8f21c-f2eb-4673-88e5-d9bcb144b780",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_single_file(dataset_path, file_dataset_path, sequence_length):\n",
    "    delimiter = \"/ \" * sequence_length\n",
    "    songs = \"\"\n",
    "    for path, _, files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(path, file)\n",
    "            with open(file_path,\"r\") as fp:\n",
    "\n",
    "                song = fp.read().strip()\n",
    "\n",
    "            songs = songs+song+\" \"+ delimiter\n",
    "    songs = songs[:-1]\n",
    "    with open (file_dataset_path, \"w\") as fp:\n",
    "        fp.write(songs)\n",
    "    return songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "03694f48-ece0-4b13-a294-3a7312f6be73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_songs_to_int(songs,mapping_path):\n",
    "    int_songs = []\n",
    "\n",
    "    # load mappings\n",
    "    with open(mapping_path, \"r\") as fp:\n",
    "        mappings = json.load(fp)\n",
    "\n",
    "    # transform songs string to list\n",
    "    songs = songs.split()\n",
    "\n",
    "    # map songs to int\n",
    "    for symbol in songs:\n",
    "        int_songs.append(mappings[symbol])\n",
    "\n",
    "    return int_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2c916e1b-da48-433d-a0a3-585460a9cf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "# Create two seperate list for original songs and cleaned songs\n",
    "songs = create_m21_songlist (kern_data_set)\n",
    "print(len(songs))\n",
    "cleaned_songs = clean_songs(songs, acceptable_note_durations)\n",
    "print(len(cleaned_songs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ffcb240-53b1-4af5-b8dd-3f4589328390",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the time series format of songs into seperate text files\n",
    "for i, song in enumerate(cleaned_songs):\n",
    "    song_text = time_series(song)\n",
    "    save_path = os.path.join(save_dir, str(i))\n",
    "    with open(save_path, \"w\") as fp:\n",
    "        fp.write(song_text)\n",
    "        \n",
    "#combine the text files into one textfile (single file data set)\n",
    "songs_single_file = create_single_file(save_dir, single_file_dataset, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6a96fab4-0e1b-4a8c-a8f4-ea82d2fb9866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create mappings\n",
    "create_mapping(songs_single_file,mapping_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4635040f-d489-471d-845d-302e08496294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of input is: (10040, 64, 17)\n",
      "The shape of input is: (10040,)\n",
      "[ 1  9  9 ... 15 15 15]\n"
     ]
    }
   ],
   "source": [
    "#generate training sequences\n",
    "def load(file_path):\n",
    "    with open(file_path, \"r\") as fp:\n",
    "        return fp.read()\n",
    "        \n",
    "songs = load(single_file_dataset)\n",
    "int_songs = convert_songs_to_int(songs,mapping_path)\n",
    "inputs = []\n",
    "targets = []\n",
    "num_sequences = len(int_songs) - sequence_length\n",
    "for i in range(num_sequences):\n",
    "    inputs.append(int_songs[i:i+sequence_length])\n",
    "    targets.append(int_songs[i+sequence_length])\n",
    "vocabulary_size = len(set(int_songs))\n",
    "\n",
    "inputs = keras.utils.to_categorical(inputs, num_classes=vocabulary_size)\n",
    "targets = np.array(targets) \n",
    "\n",
    "print(f\"The shape of input is: {inputs.shape}\")\n",
    "print(f\"The shape of input is: {targets.shape}\")\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd86152-fef5-479f-aa67-c02aed08ca05",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3909db9f-9b7a-4bde-9575-32b328494b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "OUTPUT_UNITS = vocabulary_size  # This is the size of the vocabulary\n",
    "NUM_NEURONS = [256]\n",
    "LOSS = \"sparse_categorical_crossentropy\"  # Typo fixed here\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "SAVE_MODEL_PATH = \"my_model.keras\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f4a586b1-6415-41fe-8579-ac18669a2d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "input_layer = keras.layers.Input(shape=(None, OUTPUT_UNITS))\n",
    "x = keras.layers.LSTM(NUM_NEURONS[0])(input_layer)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "output_layer = keras.layers.Dense(OUTPUT_UNITS, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs=input_layer, outputs=output_layer,name=\"my_melody_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4f6ba6db-8737-4e8b-9acc-2d7ece3c333f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#compile model\n",
    "model.compile(loss = LOSS,\n",
    "              optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "              metrics=[\"accuracy\"])\n",
    "                #model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8509fcea-a06e-4f66-96bb-85937fd37333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 179ms/step - accuracy: 0.7661 - loss: 1.2164\n",
      "Epoch 2/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 216ms/step - accuracy: 0.8187 - loss: 0.8235\n",
      "Epoch 3/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 249ms/step - accuracy: 0.8305 - loss: 0.7099\n",
      "Epoch 4/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 243ms/step - accuracy: 0.8484 - loss: 0.5255\n",
      "Epoch 5/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 238ms/step - accuracy: 0.8650 - loss: 0.4341\n",
      "Epoch 6/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 239ms/step - accuracy: 0.8701 - loss: 0.4109\n",
      "Epoch 7/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 237ms/step - accuracy: 0.8737 - loss: 0.3770\n",
      "Epoch 8/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 224ms/step - accuracy: 0.8586 - loss: 0.5130\n",
      "Epoch 9/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 183ms/step - accuracy: 0.8828 - loss: 0.3727\n",
      "Epoch 10/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 215ms/step - accuracy: 0.8874 - loss: 0.3388\n",
      "Epoch 11/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 212ms/step - accuracy: 0.8920 - loss: 0.3283\n",
      "Epoch 12/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 251ms/step - accuracy: 0.8944 - loss: 0.3239\n",
      "Epoch 13/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 230ms/step - accuracy: 0.8935 - loss: 0.3073\n",
      "Epoch 14/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 235ms/step - accuracy: 0.8944 - loss: 0.3182\n",
      "Epoch 15/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 239ms/step - accuracy: 0.9044 - loss: 0.2836\n",
      "Epoch 16/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 209ms/step - accuracy: 0.9004 - loss: 0.2879\n",
      "Epoch 17/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 213ms/step - accuracy: 0.9017 - loss: 0.2846\n",
      "Epoch 18/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 178ms/step - accuracy: 0.9040 - loss: 0.2938\n",
      "Epoch 19/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 221ms/step - accuracy: 0.9059 - loss: 0.2702\n",
      "Epoch 20/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 193ms/step - accuracy: 0.9155 - loss: 0.2601\n",
      "Epoch 21/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 184ms/step - accuracy: 0.9103 - loss: 0.2557\n",
      "Epoch 22/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 202ms/step - accuracy: 0.9080 - loss: 0.2523\n",
      "Epoch 23/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.9206 - loss: 0.2315\n",
      "Epoch 24/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 206ms/step - accuracy: 0.9146 - loss: 0.2376\n",
      "Epoch 25/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 193ms/step - accuracy: 0.9221 - loss: 0.2134\n",
      "Epoch 26/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 198ms/step - accuracy: 0.8706 - loss: 0.4034\n",
      "Epoch 27/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 192ms/step - accuracy: 0.9173 - loss: 0.2315\n",
      "Epoch 28/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 184ms/step - accuracy: 0.9242 - loss: 0.2122\n",
      "Epoch 29/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 188ms/step - accuracy: 0.9179 - loss: 0.2122\n",
      "Epoch 30/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 207ms/step - accuracy: 0.9238 - loss: 0.2055\n",
      "Epoch 31/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.9350 - loss: 0.1809\n",
      "Epoch 32/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 207ms/step - accuracy: 0.9357 - loss: 0.1808\n",
      "Epoch 33/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 190ms/step - accuracy: 0.9276 - loss: 0.1861\n",
      "Epoch 34/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 208ms/step - accuracy: 0.9340 - loss: 0.1790\n",
      "Epoch 35/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 179ms/step - accuracy: 0.9349 - loss: 0.1729\n",
      "Epoch 36/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 206ms/step - accuracy: 0.9333 - loss: 0.1717\n",
      "Epoch 37/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 180ms/step - accuracy: 0.9433 - loss: 0.1551\n",
      "Epoch 38/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 184ms/step - accuracy: 0.9420 - loss: 0.1551\n",
      "Epoch 39/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 187ms/step - accuracy: 0.9401 - loss: 0.1619\n",
      "Epoch 40/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 194ms/step - accuracy: 0.9473 - loss: 0.1438\n",
      "Epoch 41/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 204ms/step - accuracy: 0.9427 - loss: 0.1569\n",
      "Epoch 42/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 185ms/step - accuracy: 0.9500 - loss: 0.1335\n",
      "Epoch 43/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 212ms/step - accuracy: 0.9471 - loss: 0.1461\n",
      "Epoch 44/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 180ms/step - accuracy: 0.9529 - loss: 0.1274\n",
      "Epoch 45/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 195ms/step - accuracy: 0.9557 - loss: 0.1207\n",
      "Epoch 46/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 199ms/step - accuracy: 0.9504 - loss: 0.1289\n",
      "Epoch 47/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.9593 - loss: 0.1075\n",
      "Epoch 48/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 184ms/step - accuracy: 0.9608 - loss: 0.1074\n",
      "Epoch 49/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 189ms/step - accuracy: 0.9196 - loss: 0.2646\n",
      "Epoch 50/50\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 186ms/step - accuracy: 0.8936 - loss: 0.3001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x16c8d3ec0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "model.fit(inputs,targets, epochs = EPOCHS, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "766ffa49-c412-4566-862d-4f38a6255c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save(SAVE_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c9813d-ca84-4f74-8982-8ccca12a06bc",
   "metadata": {},
   "source": [
    "# Generating melody from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2c479b51-45c0-4c7e-aa0e-575d4647a5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MelodyGenerator:\n",
    "    def __init__(self, model_path=SAVE_MODEL_PATH):\n",
    "        self.model_path = model_path\n",
    "        self.model = keras.models.load_model(model_path)\n",
    "\n",
    "        # Load mapping\n",
    "        with open(mapping_path, \"r\") as fp:\n",
    "            self._mappings = json.load(fp)\n",
    "\n",
    "        self._start_symbols = [\"/\"] * sequence_length\n",
    "\n",
    "    def generate_melody(self, seed, num_steps, max_sequence_length):\n",
    "        seed = seed.split()\n",
    "        melody = seed.copy()\n",
    "\n",
    "        # Add start symbols\n",
    "        seed = self._start_symbols + seed\n",
    "\n",
    "        # Map seed to integers\n",
    "        seed = [self._mappings[symbol] for symbol in seed]\n",
    "\n",
    "        for n in range(num_steps):\n",
    "            #print(f\"compositing note {n}\")\n",
    "            # Keep only the last `max_sequence_length` items\n",
    "            seed_input = seed[-max_sequence_length:]\n",
    "\n",
    "            # One-hot encode\n",
    "            one_hot_seed = keras.utils.to_categorical(seed_input, num_classes=vocabulary_size)\n",
    "\n",
    "            # Add batch dimension\n",
    "            one_hot_seed = np.expand_dims(one_hot_seed, axis=0)\n",
    "\n",
    "            # Predict next token\n",
    "            probabilities = self.model.predict(one_hot_seed, verbose=0)[0]\n",
    "            output_int = np.argmax(probabilities)\n",
    "\n",
    "            # Append prediction\n",
    "            seed.append(output_int)\n",
    "\n",
    "            # Map back to symbol\n",
    "            output_symbol = [k for k, v in self._mappings.items() if v == output_int][0]\n",
    "\n",
    "            # End if end symbol\n",
    "            if output_symbol == \"/\":\n",
    "                break\n",
    "\n",
    "            melody.append(output_symbol)\n",
    "\n",
    "        return melody\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e8acffcf-eb0e-437e-94de-89c87270db17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['64', '_', '_', '_', '65', '_', '_', '_', '67', '_', '_', '_', '_', '_', '_', '_', '71', '_', '_', '_', '_', '_', '_', '_', '71', '_', '_', '_', '_', '_', '_', '_', '67', '_', '_', '_', '_', '_', '_', '_', '67', '_', '_', '_', '_', '_', '_', '_', '64', '_', '_', '_', '65', '_', '_', '_', '64', '_', '_', '_', '_', '_', '_', '_', '60', '_', '_', '_', '_', '_', '_', '_']\n"
     ]
    }
   ],
   "source": [
    "mg = MelodyGenerator()\n",
    "seed = \"64 _ _ _ 65 _ _ _ 67 _ _ _ _ _ _ _ 71 _ _ _ _ _ _ _ 71 \"\n",
    "composition = mg.generate_melody(seed, 50, sequence_length)\n",
    "print(composition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "50e380d7-b4af-41ab-b052-4de3ee63f497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting output in musescore\n",
    "step_duration=0.25\n",
    "format=\"midi\"\n",
    "file_name=\"composition.mid\"\n",
    "\n",
    "# create a music21 stream\n",
    "stream = m21.stream.Stream()\n",
    "\n",
    "start_symbol = None\n",
    "step_counter = 1\n",
    "\n",
    "# parse all the symbols in the melody and create note/rest objects\n",
    "for i, symbol in enumerate(composition):\n",
    "\n",
    "    # handle case in which we have a note/rest\n",
    "    if symbol != \"_\" or i + 1 == len(composition):\n",
    "\n",
    "        # ensure we're dealing with note/rest beyond the first one\n",
    "        if start_symbol is not None:\n",
    "\n",
    "            quarter_length_duration = step_duration * step_counter # 0.25 * 4 = 1\n",
    "\n",
    "            # handle rest\n",
    "            if start_symbol == \"r\":\n",
    "                m21_event = m21.note.Rest(quarterLength=quarter_length_duration)\n",
    "\n",
    "            # handle note\n",
    "            else:\n",
    "                m21_event = m21.note.Note(int(start_symbol), quarterLength=quarter_length_duration)\n",
    "\n",
    "            stream.append(m21_event)\n",
    "\n",
    "            # reset the step counter\n",
    "            step_counter = 1\n",
    "\n",
    "        start_symbol = symbol\n",
    "\n",
    "    # handle case in which we have a prolongation sign \"_\"\n",
    "    else:\n",
    "        step_counter += 1\n",
    "\n",
    "# write the m21 stream to a midi file\n",
    "stream.write(format, file_name)\n",
    "\n",
    "\n",
    "# Load your MIDI file\n",
    "score = converter.parse(\"composition.mid\")\n",
    "\n",
    "# Show in MuseScore\n",
    "score.show('musicxml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3460263a-2b05-4f6b-b7ae-b069e479f0c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
